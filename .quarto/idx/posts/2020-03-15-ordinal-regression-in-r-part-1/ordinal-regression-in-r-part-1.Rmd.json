{"title":"Ordinal regression in R: part 1","markdown":{"yaml":{"title":"Ordinal regression in R: part 1","description":"A theoretical and applied walkthrough of ordinal regression.\nPart 1: the frequentist approach with `ordinal`.\n","author":[{"name":"Taylor Dunn"}],"date":"2020-03-15","params":{"date":"2020-03-15","slug":"ordinal-regression-in-r-part-1"},"categories":["regression","ordinal","frequentist statistics"],"output":{"distill::distill_article":{"self_contained":false,"toc":true}},"bibliography":"references.bib"},"headingText":"Setup","containsRefs":false,"markdown":"\n\n```{r setup, include=TRUE, code_folding=\"R packages\"}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\nlibrary(dunnr)\nlibrary(gt)\nlibrary(broom)\nlibrary(patchwork)\n\nextrafont::loadfonts(device = \"win\", quiet = TRUE)\ntheme_set(theme_td())\nset_geom_fonts()\nset_palette()\n\nwine_red <- \"#58181F\"\nupdate_geom_defaults(\"point\", list(color = wine_red))\nupdate_geom_defaults(\"line\", list(color = wine_red))\n```\n\nThe purpose of this post is to learn more about ordinal regression models (a.k.a. cumulative link, proportional odds, ordered logit models, etc.) and practice their implementation in R.\nThis is part 1, where I'll be taking the frequentist approach via the [`ordinal` package](https://cran.r-project.org/web/packages/ordinal/index.html).\nThere are other options, like `MASS::polr`, but two features in particular drew me to `ordinal`: (1) it allows for random effects, and (2) it has [`broom::tidy` methods](https://rdrr.io/cran/broom/man/ordinal_tidiers.html) available.\n\nParticularly, I'll be following along with\n\n* this excellent [primer](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/ordinal/inst/doc/primer.pdf?revision=66&root=ordinal&pathrev=69) which includes theory and application, and\n* this [vignette](https://cran.r-project.org/web/packages/ordinal/vignettes/clmm2_tutorial.pdf) which is a tutorial on incorporating random effects.\n\n\nImport `ordinal`, and the included data set `wine`:\n\n```{r}\nlibrary(ordinal)\ndata(wine)\nwine <- as_tibble(wine)\nglimpse(wine)\n```\n\n`wine` is a data set from @Randall1989 of wine bitterness ratings from multiple judges.\nThe variables are as follows:\n\n* Outcome:\n    * `response`: wine bitterness rating on a 0-100 scale\n    * `rating`: ordered factor with 5 levels (grouped version of `response`) with 1 = \"least bitter\" and 5 = \"most bitter\"\n* Treatment factors:\n    * `temp`: temperature during wine production (`r str_c(unique(wine$temp), collapse = \" and \")`)\n    * `contact`: contact between juice and skins during wine production (`r str_c(unique(wine$contact), collapse = \" and \")`)\n* Random effects\n    * `bottle` with `r nlevels(wine$bottle)` levels\n    * `judge` with `r nlevels(wine$judge)` levels\n\nRelationship between `response` and `rating`:\n\n```{r fig.height=3, fig.width=5}\nwine %>%\n  ggplot(aes(y = rating, x = response)) +\n  geom_boxplot(width = 0.5) +\n  geom_jitter(alpha = 0.5)\n```\n\nNote that there is no overlap between the levels.\n\nThere are `r nrow(wine)` total observations with the following ratings distribution by treatment and random effects:\n\n```{r}\nwine %>%\n  transmute(temp, contact, bottle, judge, rating = as.numeric(rating)) %>%\n  pivot_wider(names_from = judge, values_from = rating) %>%\n  gt() %>%\n  tab_spanner(columns = `1`:`9`, label = \"judge\") %>%\n  data_color(\n    columns = `1`:`9`,\n    colors = scales::col_numeric(\n      palette = c(\"white\", wine_red), domain = c(1, 5)\n    )\n  )\n```\n\nSo each `bottle` had a particular `temp` and `contact` (2 bottles for each of the 4 combinations), and each `judge` rated the bitterness each bottle.\n\nBefore modeling, can we see a clear effect of `temp` and `contact`?\n\n```{r fig.width=5, fig.height=3}\nwine %>%\n  count(contact, rating, temp) %>%\n  mutate(temp = fct_rev(temp)) %>%\n  ggplot(aes(x = temp, y = rating, color = temp)) +\n  geom_point(aes(group = temp, size = n)) +\n  facet_wrap(~contact, scales = \"free_x\",\n             labeller = labeller(contact = label_both)) +\n  scale_size(breaks = c(1, 2, 4, 6, 8)) +\n  add_facet_borders()\n```\n\nAt a glance, it looks like the `temp` = warm and `contact` = yes is associated with higher `rating`s.\n\n## The cumulative link model\n\n### Theory\n\nThe ordinal response $y_i$ falls into response category $j$ (out of $J$ total) with probability $\\pi_{ij}$.\nThe cumulative probabilities are defined:\n\n$$\nP(y_i \\leq j) = \\pi_{i1} + \\dots + \\pi_{ij}.\n$$\n\nAs an oversimplification, suppose that each probability $\\pi_{ij}$ is equal to the proportion of that response in the `wine` data.\nThen the cumulative \"probability\" can be visualized:\n\n```{r fig.width=8, fig.height=4}\nwine_prop <- wine %>%\n  count(rating) %>%\n  mutate(p = n / sum(n), cumsum_p = cumsum(p))\n\n(\n  ggplot(wine_prop, aes(x = rating, y = p)) +\n    geom_col(fill = wine_red) +\n    scale_y_continuous(labels = scales::percent, expand = c(0, 0)) +\n    labs(x = \"j\", y = \"proportion\")\n) +\n  (\n    ggplot(wine_prop, aes(x = as.integer(rating), y = cumsum_p)) +\n      geom_point(size = 2) +\n      geom_line(size = 1) +\n      labs(x = \"j\", y = \"cumulative proportion\")\n  ) +\n  (\n    ggplot(wine_prop,\n        aes(x = as.integer(rating), y = log(cumsum_p) - log(1 - cumsum_p))) +\n      geom_point(size = 2) +\n      geom_line(size = 1) +\n      labs(x = \"j\", y = \"logit(cumulative proportion)\")\n  )\n```\n\nWe will explore other links, but first the most common, the logit link, which is depicted in the right-most panel of the above figure:\n\n$$\n\\text{logit} (P(y_i \\leq j) = \\log \\frac{P(y_i \\leq j)}{1 - P(y_i \\leq j)}\n$$\n\nNote that the above function is defined for all but the last category $j = J$, because $1 - P(Y_i \\leq J) = 1 - 1 = 0$.\n\nFor the `wine` data, where we have $J$ = 5 rating categories, we will build up to the following mixed effects model:\n\n$$\n\\begin{align}\n\\text{logit}(p(y_i \\leq j)) &= \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i - u( \\text{judge}_i) \\\\\ni &= 1, \\dots n \\; \\; \\; \\; \\; \\; j = 1, \\dots, J - 1\n\\end{align}\n$$\n\nwhere $\\theta_j$ is called the threshold parameter, or cutpoint, of category $j$.\nThese thresholds can also be thought of as $J-1$ = 4 intercepts.\nNote that the fixed effect parameters $\\beta_1$ and $\\beta_2$ are independent of $j$, so each $\\beta$ has the same effect for each of the $J-1$ cumulative logits.\nThe judge effects, which are also independent of $j$, are assumed normal: $u(\\text{judge}_i) \\sim N(0, \\sigma_u^2)$.\nWe are using the logit link because it is the most popular for this kind of model (and the one I am familiar with), but there are other options we will briefly explore later.\n\nThe subtraction of terms in the above model is new to me.\nThe main reason seems to be for familiar interpretation: the larger the value of any independent term $\\beta x$, the smaller the thresholds $\\theta_j$, and therefore a larger probability of the a response falling into a category at the upper end of the scale.\nThis way, $\\beta$ has the same *direction* of effect as in ordinary linear regression.\n\nWe are essentially modeling a \"chain\" of logistic regressions where the binary response is \"less than or equal to a certain level\" vs \"greater than that level\".\nIn this case, with $J$ = 5, the thresholds $\\theta_j$ are capturing the adjusted log-odds of observing:\n\n* $j$ = 1: log-odds of `rating` = 1 vs. 2-5\n* $j$ = 2: log-odds of `rating` = 1-2 vs. 3-5\n* $j$ = 3: log-odds of `rating` = 1-3 vs. 4-5\n* $j$ = 4: log-odds of `rating` = 1-4 vs. 5\n\n### Fitting\n\nNow with a surface-level understanding of what is being modeled, we will fit the data using `ordinal::clm` (cumulative link models) and `ordinal::clmm` (cumulative link mixed models), and logit links.\n\n#### Fixed effects model\n\nFirst, fit a simple model, by maximum likelihood, with `contact` as the sole predictor:\n\n$$\n\\text{logit}(p(y_i \\leq j)) = \\theta_j - \\beta_2 \\text{contact}_i\n$$\n\n```{r}\nclm_rating_contact <-\n  clm(\n    rating ~ contact,\n    data = wine, link = \"logit\"\n  )\nsummary(clm_rating_contact)\n```\n\nThe model gives us $K - 1 = 4$ threshold coefficients, as expected.\nThe $\\beta_2$ coefficient estimate was statistically significant (by a Wald test), and tells us that `contact` = yes *decreases* the thresholds $\\theta_j$ by $\\beta_2$ = `r round(tidy(clm_rating_contact)$estimate[5], 2)` (because of the subtraction of model terms), and therefore is associated with *higher* `rating`s.\n\nThe condition number of the Hessian for this model is `r round(clm_rating_contact$cond.H, 2)`.\nThe `ordinal` primer says that larger values (like > `1e4`) might indicate that the model is ill-defined.\n\nIt is nicely illustrative to compare this model to 4 separate logistic regressions with a dichotomized response:\n\n$$\n\\begin{align}\n\\text{logit} (p(y_i \\leq 1)) = \\theta_1 + \\beta_2 \\text{contact_i} \\\\\n\\text{logit} (p(y_i \\leq 2)) = \\theta_2 + \\beta_2 \\text{contact_i} \\\\\n\\text{logit} (p(y_i \\leq 3)) = \\theta_3 + \\beta_2 \\text{contact_i} \\\\\n\\text{logit} (p(y_i \\leq 4)) = \\theta_4 + \\beta_2 \\text{contact_i} \\\\\n\\end{align}\n$$\n\n```{r warning=F}\nwine %>%\n  crossing(j = 1:4) %>%\n  # Create a binary (0 or 1) to indicate where rating <= j\n  mutate(rating_leq_j = as.numeric(rating) <= j) %>%\n  group_by(j) %>%\n  nest() %>%\n  ungroup() %>%\n  mutate(\n    mod = map(\n      data,\n      ~glm(rating_leq_j ~ 1 + contact,\n           data = ., family = binomial(link = \"logit\")) %>% broom::tidy()\n    )\n  ) %>%\n  unnest(mod) %>%\n  transmute(\n    j, term,\n    estimate_se = str_c(round(estimate, 2), \" (\", round(std.error, 2), \")\")\n  ) %>%\n  pivot_wider(names_from = term, values_from = estimate_se) %>%\n  left_join(\n    tidy(clm_rating_contact) %>%\n      transmute(\n        j = as.integer(substr(term, 1, 1)),\n        term = if_else(!is.na(j), \"theta_j\", term),\n        estimate_se = str_c(round(estimate, 2), \" (\", round(std.error, 2), \")\")\n      ) %>%\n      mutate(j = replace_na(j, 1)) %>%\n      spread(term, estimate_se),\n    by = \"j\"\n  ) %>%\n  ungroup() %>%\n  gt() %>%\n  tab_spanner(label = \"Logistic regression\",\n              columns = vars(`(Intercept)`, contactyes.x)) %>%\n  tab_spanner(label = \"CLM\",\n              columns = vars(theta_j, contactyes.y)) %>%\n  fmt_missing(columns = everything(), missing_text = \"\")\n```\n\nThe intercepts from the ordinary logistic regression correspond closely to the threshold parameters $\\theta_j$ from the cumulative link model.\nIn the fixed effect of `contact` ($\\beta_2$), first note the sign difference, and second notice that the estimate from CLM is about the average of the 4 estimates from logistic regression.\nThe advantage of the CLM is seen in the small standard error in the $\\beta_2$ estimate.\n\nTo quote the primer:\n\n>The cumulative logit model can be seen as the model that combines these four ordinary logistic regression models into a single model and therefore makes better use of the information in the data.\n\nFor the second model, we add the $\\beta_1 \\text{temp}_i$ term:\n\n$$\n\\text{logit}(p(y_i \\leq j)) = \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i\n$$\n\n```{r}\nclm_rating_contact_temp <-\n  clm(\n    rating ~ contact + temp,\n    data = wine, link = \"logit\"\n  )\nsummary(clm_rating_contact_temp)\n```\n\nBoth fixed effects (`contact` = yes and `temp` = warm) are strongly associated with higher probability of higher ratings.\nThe `summary` function provides $p$-values from Wald tests, but more accurate likelihood ratio tests can be done via the `drop1` function, which evaluates each fixed effect while controlling the other:\n\n```{r}\ndrop1(clm_rating_contact_temp, test = \"Chisq\")\n```\n\nOr the reverse via the `add1()` function, which evaluates each fixed effect while ignoring the other:\n\n```{r}\n# Fit the null model first\nclm_rating_null <- clm(rating ~ 1, data = wine, link = \"logit\")\nadd1(clm_rating_null, scope = ~ contact + temp, test = \"Chisq\")\n```\n\nSymmetric Wald confidence intervals can be extracted with `confint` or with `broom::tidy`:\n\n```{r fig.height=2, fig.width=5}\ntidy(clm_rating_contact_temp, conf.int = TRUE, conf.type = \"Wald\") %>%\n  ggplot(aes(y = term, x = estimate)) +\n  geom_point(size = 2) +\n  geom_linerange(size = 1, aes(xmin = conf.low, xmax = conf.high))\n```\n\nIn these types of analyses, we are often interested in the odds ratios.\nFor the two categorical fixed effects, which have two levels each, the odds ratios $y \\leq j$ comparing the two levels are:\n\n$$\n\\begin{align}\n\\text{OR} &= \\frac{\\gamma_j (\\text{temp} = \\text{warm})}{\\gamma_j (\\text{temp} = \\text{cold})} = \\frac{\\exp(\\theta_j - \\beta_1 - \\beta_2 \\text{contact})}{\\exp (\\theta_j - 0 - \\beta_2 \\text{contact}}) = \\exp(\\beta_1) \\\\\n\\text{OR} &= \\frac{\\gamma_j (\\text{contact} = \\text{yes})}{\\gamma_j (\\text{contact} = \\text{no})} = \\frac{\\exp(\\theta_j - \\beta_1 \\text{temp} - \\beta_2 )}{\\exp (\\theta_j - \\beta_1 \\text{temp} - 0)}) = \\exp(\\beta_2)\n\\end{align}\n$$\n\nwhere we have introduced the shorthand $\\gamma_j = \\text{logit} (p(y \\leq j))$.\nCompute those odds ratios, and their corresponding Wald 95% CIs:\n\n```{r}\ntidy(clm_rating_contact_temp, conf.int = T, conf.type = \"Wald\") %>%\n  transmute(\n    term, across(c(estimate, conf.low, conf.high), exp)\n  ) %>%\n  gt() %>%\n  fmt_number(c(estimate, conf.low, conf.high), decimals = 2)\n```\n\nOne last thing to check: does the data support an interaction between $\\text{temp}_i$ and $\\text{contact}_i$?\n\n$$\n\\text{logit}(p(y_i \\leq j)) = \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i - \\beta_3 \\text{temp}_i \\text{contact}_i\n$$\n\n```{r}\nclm_rating_contact_temp_inter <-\n  clm(\n    rating ~ contact * temp, data = wine, link = \"logit\"\n  )\n\n#drop1(clm_rating_contact_temp_inter, test = \"Chisq\") # this accomplishes the same thing as anova()\nanova(clm_rating_contact_temp, clm_rating_contact_temp_inter)\n```\n\nNo, The interaction term `contact:temp` is not supported by the data.\n\n##### Comparison to linear model\n\nConsider the following linear model which treats `rating` as continuous:\n\n$$\ny_i = \\alpha + \\beta_1 \\text{temp}_i + \\beta_2 \\text{contact}_i + \\epsilon_i\n$$\n\nwhere $\\epsilon_i \\sim N(0, \\sigma_{\\epsilon}^2)$.\n\n```{r}\nlm_rating_contact_temp <- lm(as.numeric(rating) ~ contact + temp, data = wine)\n```\n\n\nTo compare this to a CLM, we must use the probit link:\n\n```{r}\nclm_rating_contact_temp_probit <-\n  clm(\n    rating ~ contact + temp, data = wine, link = \"probit\"\n  )\ntidy(clm_rating_contact_temp_probit) %>%\n  filter(coef.type == \"location\") %>%\n  mutate(model = \"CLM\") %>%\n  select(-coef.type) %>%\n  bind_rows(\n    tidy(lm_rating_contact_temp) %>%\n      filter(term != \"(Intercept)\") %>%\n      # Need to divide by the residual SE here to get the right scale\n      mutate(estimate = estimate / summary(lm_rating_contact_temp)$sigma,\n             model = \"LM\")\n  ) %>%\n  group_by(model) %>%\n  gt() %>%\n  fmt_number(c(estimate, std.error, statistic), decimals = 2) %>%\n  fmt(p.value, fns = scales::pvalue)\n```\n\nThe relative estimates from the linear model are lower than those from the CLM (probit link), indicating that the assumptions of the linear model are not met.\nIn particular, the distance between thresholds is not equidistant, as we can see from differences in the CLM coefficients:\n\n```{r}\ndiff(coef(clm_rating_contact_temp_probit)[1:4]) %>% round(2)\n```\n\n#### Mixed effects model\n\nNow that we have explored ordinal regression with just fixed effects, we will fit the following random effects model:\n\n$$\n\\begin{align}\n\\text{logit}(p(y_i \\leq j)) &= \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i - u( \\text{judge}_i) \\\\\ni &= 1, \\dots n \\; \\; \\; \\; \\; \\; j = 1, \\dots, J - 1\n\\end{align}\n$$\n\nwhere the judge effects are independent of $j$, and assumed normal: $u(\\text{judge}_i) \\sim N(0, \\sigma_u^2)$.\n\nEach judge has 8 `rating`s each (two per combination of `temp` and `contact`).\nSee if we can spot the `judge` variance in a plot of `rating`s:\n\n```{r fig.height=3, fig.width=5}\nwine %>%\n  count(judge, rating) %>%\n  ggplot(aes(x = judge, y = rating)) +\n  geom_tile(aes(fill = n)) +\n  geom_text(aes(label = n), color = \"white\") +\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0)) +\n  theme(legend.position = \"none\") +\n  labs(title = \"Number of ratings by judge\")\n```\n\nThere is definitely some judge-specific variability in the perception of bitterness of wine.\n`judge` 5, for instance, doesn't stray far from `rating` = 3, while `judge` 7 didn't consider any of the wines particularly bitter.\n\nFit the full model with `ordinal::clmm` and logit link:\n\n```{r}\nclmm_rating_contact_temp <-\n  clmm(\n    rating ~ temp + contact + (1|judge),\n    data = wine, link = \"logit\"\n  )\n# This is an older function, which we need to run stats::profile later\nclmm2_rating_contact_temp <-\n  clmm2(\n    rating ~ temp + contact, random = judge,\n    data = wine, link = \"logistic\"\n  )\nsummary(clmm_rating_contact_temp)\n```\n\nCompare model coefficients:\n\n```{r}\nbind_rows(\n  CLM = tidy(clm_rating_contact_temp),\n  CLMM = tidy(clmm_rating_contact_temp),\n  .id = \"model\"\n) %>%\n  select(-coef.type) %>%\n  group_by(model) %>%\n  gt() %>%\n  fmt_number(c(estimate, std.error, statistic), decimals = 2) %>%\n  fmt(p.value, fns = scales::pvalue)\n```\n\nBoth fixed effect estimates $\\beta_1$ and $\\beta_2$ are higher in the CLMM.\nUse `anova` to compare the CLMM to the CLM:\n\n```{r}\nanova(clm_rating_contact_temp, clmm_rating_contact_temp)\n```\n\nUnsurprisingly, the `judge` term makes a significant improvement to the fit.\nWe can extract profile confidence intervals on the variance $\\sigma_u$ using `stats::profile`:\n\n```{r}\nprofile(clmm2_rating_contact_temp,\n        range = c(0.1, 4), nSteps = 30, trace = 0) %>%\n  confint()\n```\n\nNote that these intervals are asymmetric ($\\sigma_u$ = 1.28), unlike the less accurate Wald tests.\nWe can produce \"best guess\" estimates for `judge` effects using *conditional modes*:\n\n```{r fig.height=3, fig.width=4}\ntibble(\n  judge_effect = clmm_rating_contact_temp$ranef,\n  cond_var = clmm_rating_contact_temp$condVar\n) %>%\n  mutate(\n    judge = fct_reorder(factor(1:n()), judge_effect),\n    conf.low = judge_effect - qnorm(0.975) * sqrt(cond_var),\n    conf.high = judge_effect + qnorm(0.975) * sqrt(cond_var)\n  ) %>%\n  ggplot(aes(y = judge, x = judge_effect)) +\n  geom_point(size = 2) +\n  geom_linerange(size = 1, aes(xmin = conf.low, xmax = conf.high)) +\n  theme(panel.grid.major.x = element_line(color = \"grey\"))\n```\n\n##### Predictions\n\nThere are different ways to extract predicted probabilities.\nFirst, and most obviously, with the `predict` function:\n\n```{r}\nwine %>%\n  bind_cols(\n    pred =  predict(\n      # Have to use clmm2 for predict\n      clmm2_rating_contact_temp, newdata = wine\n    )\n  ) %>%\n  # These are predicted probabilities for the average judge, so we can\n  #  exclude the judge variable\n  distinct(rating, temp, contact, pred) %>%\n  arrange(temp, contact, rating)\n```\n\nThis only gives us predictions for `rating`, `temp` and `contact` values which exist in the data.\nThere is no predicted probability for `rating` > 3, `temp` cold and `contact` no, for example.\n\nAnother way is to pre-specify which values we want to predict:\n\n```{r fig.height=3, fig.width=5, preview=TRUE}\nnd <-\n  crossing(\n    temp = factor(c(\"cold\", \"warm\")),\n    contact = factor(c(\"no\", \"yes\")),\n    rating = factor(1:5, ordered = T)\n  )\nnd %>%\n  bind_cols(pred = predict(clmm2_rating_contact_temp, nd)) %>%\n  ggplot(aes(x = glue::glue(\"{temp}-{contact}\"), y = pred, fill = rating)) +\n  geom_col() +\n  scale_fill_td(palette = \"div5\") +\n  scale_y_continuous(expand = c(0, 0), labels = scales::percent) +\n  labs(x = \"temp-contact\", y = \"predicted probability\")\n```\n\nWe can also get model-estimated cumulative probabilities by considering the model coefficients.\nFor example, for a cold `temp` and `contact`, the cumulative probability of a bitterness `rating` $j$ or less:\n\n$$\nP(y_i \\leq j) = \\text{logit}^{-1} [\\theta_j - \\beta_2 \\text{contact}_i]\n$$\n\nwhere we are considering the average judge ($u(\\text{judge}_i) = 0$).\nThe inverse logit is $\\text{logit}^{-1}(x) = 1 / (1 + \\exp(-x))$, and can be calculated with `plogis` as a shorthand (`brms::inv_logit_scaled` is another).\nWe can subtract cumulative probabilities to get non-cumulative probabilities of a rating $j$.\nFor example, $j$ = 3:\n\n```{r}\nplogis(clmm_rating_contact_temp$Theta[3] - clmm_rating_contact_temp$beta[2]) -\n  plogis(clmm_rating_contact_temp$Theta[2] - clmm_rating_contact_temp$beta[2])\n```\n\nwhich matches the value calculated previously using `predict`.\n\n```{r eval=FALSE, include=FALSE}\n# Just checking the plogis() calculation\ntidy(clmm_rating_contact_temp) %>%\n  select(term, estimate) %>%\n  filter(term != \"tempwarm\") %>%\n  spread(term, estimate) %>%\n  gather(term, estimate, -contactyes) %>%\n  mutate(\n    prob_manual = 1 / (1 + exp(-estimate + contactyes)),\n    prob_plogis = plogis(estimate - contactyes)\n  )\n```\n\n##### Estimated marginal means\n\nThe `emmeans` package provides functionality for estimating marginal mean effects of ordinal models.\nThe package documentation also provides an example using `ordinal` and `wine` data [here](https://cran.r-project.org/web/packages/emmeans/vignettes/sophisticated.html#ordinal).\n\n```{r message=FALSE}\nlibrary(emmeans)\n```\n\nIn the \"Models supported by `emmeans`\" document, we see the following:\n\n| Object.class | Package | Group | Arguments/notes                                                                                 |   |\n|--------------|---------|-------|-------------------------------------------------------------------------------------------------|---|\n| clm          | ordinal | O     | `mode = c(\"latent\", \"linear.predictor\", \"cum.prob\", \"exc.prob\", \"prob\", \"mean.class\", \"scale\")` |   |\n| clmm         | ordinal | O     | Like `clm` but no `\"scale\"` mode                                                                |   |\n|              |         |       |                                                                                                 |   |\n\n```{r message=FALSE}\nemmeans(clmm_rating_contact_temp,\n        specs = list(pairwise ~ temp, pairwise ~ contact), mode = \"latent\")\n```\n\nThe contrast estimates are in terms of the latent (underlying unobserved) bitterness `rating`.\n\nUsing `mode = \"cum.prob\"` and `mode = \"exc.prob`\", we can get cumulative probabilities and exceedance (1 - cumulative) probabilities.\nFor example, the probability of a `rating` of at least 4 for different `temp`:\n\n```{r}\nemmeans(clmm_rating_contact_temp, ~ temp,\n        mode = \"exc.prob\", at = list(cut = \"3|4\"))\n```\n`mode = \"prob\"` gives us probability distributions of each `rating`, which have a nice auto `plot` functionality:\n\n```{r fig.height=3, fig.width=5}\nemmeans(clmm_rating_contact_temp,\n        ~ rating | temp, mode = \"prob\") %>%\n  plot() +\n  add_facet_borders()\n```\n\n\n##### Choice of link function\n\nSo far, we have used the logit link (and briefly the probit link to compare estimates with linear regression).\nThe links available to `ordinal::clmm` are logit, probit, cloglog, loglog, and cauchit.\n\nWe can fit the CLMM using all of these links and compare log-likelihoods:\n\n```{r}\nwine %>%\n  nest(everything()) %>%\n  crossing(\n    link = c(\"logit\", \"probit\", \"cloglog\", \"loglog\", \"cauchit\")\n  ) %>%\n  mutate(\n    mod = map2(\n      data, link,\n      ~clmm(\n        rating ~ 1 + contact + temp + (1|judge),\n        data = .x, link = .y\n      )\n    )\n  ) %>%\n  mutate(mod_summary = map(mod, glance)) %>%\n  unnest(mod_summary) %>%\n  select(link, logLik, AIC, BIC) %>%\n  arrange(logLik)\n```\n\nThe probit model appears to be the best description of the data.\n\nWe can also consider the effect of \"flexible\" vs \"equidistant\" thresholds:\n\n```{r}\nwine %>%\n  nest(data = everything()) %>%\n  crossing(\n    link = c(\"logit\", \"probit\", \"cloglog\", \"loglog\", \"cauchit\"),\n    threshold = c(\"flexible\", \"equidistant\")\n  ) %>%\n  mutate(\n    mod = pmap(\n      list(data, link, threshold),\n      function(a, b, c) {\n        clmm(\n          rating ~ 1 + contact + temp + (1|judge),\n          data = a, link = b, threshold = c\n        )\n      }\n    )\n  ) %>%\n  #mutate(mod_summary = map(mod, glance)) %>%\n  mutate(\n    mod_summary = map(\n      mod,\n      # glance() on a clmm object returns a <logLik> variable type which\n      #  can't be bound together by unnest(), so need to convert it to numeric\n      ~glance(.x) %>% mutate(logLik = as.numeric(logLik))\n    )\n  ) %>%\n  unnest(mod_summary) %>%\n  select(link, threshold, logLik, edf, AIC, BIC) %>%\n  arrange(logLik)\n```\n\nNote the change in degrees of freedom, resulting in the equidistant probit model having the lowest BIC.\nIn terms of log likelihood, however, flexible always outperform equidistant thresholds.\n\n## Conclusion\n\nThanks to detailed documentation, fitting cumulative link (mixed) models is very easy with `ordinal`.\nIn this post, we first learned the theoretical basis for these models, then worked through examples using `wine` bitterness ratings from multiple judges.\n\nIn the next post, I'll explore the Bayesian approach to ordinal regression with the `brms` package.\n\n## Reproducibility {.appendix}\n\n<details><summary>Session info</summary>\n\n```{r echo=FALSE}\ndevtools::session_info()$platform\ndevtools::session_info()$packages %>%\n  rmarkdown::paged_table()\n```\n\n</details>\n\n<details><summary>Git repository</summary>\n\n```{r echo=FALSE}\ngit2r::repository()\n```\n\n</details>\n\n```{r echo=FALSE}\ndunnr::get_distill_source(date = params$date, slug = params$slug)\n```\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":{"distill::distill_article":{"self_contained":false,"toc":true}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"message":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"ordinal-regression-in-r-part-1.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.15","theme":"cosmo","title-block-banner":true,"license":"CC BY","toc-title":"Table of contents","toc-location":"left","author":[{"name":"Taylor Dunn","url":"https://tdunn.ca","affiliation":"Ardea Outcomes","affiliation-url":"https://ardeaoutcomes.com/","orcid":"0000-0001-8042-1611"},{"name":"Taylor Dunn"}],"citation":true,"title":"Ordinal regression in R: part 1","description":"A theoretical and applied walkthrough of ordinal regression.\nPart 1: the frequentist approach with `ordinal`.\n","date":"2020-03-15","params":{"date":"2020-03-15","slug":"ordinal-regression-in-r-part-1"},"categories":["regression","ordinal","frequentist statistics"],"bibliography":["references.bib"]},"extensions":{"book":{"multiFile":true}}}}}