[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "news\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2022\n\n\nTaylor Dunn, Harlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2022\n\n\nTaylor Dunn, Tristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nregression\n\n\nordinal\n\n\nfrequentist statistics\n\n\n\n\nA theoretical and applied walkthrough of ordinal regression. Part 1: the frequentist approach with ordinal.\n\n\n\n\n\n\nMar 15, 2020\n\n\nTaylor Dunn\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html",
    "href": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html",
    "title": "Ordinal regression in R: part 1",
    "section": "",
    "text": "R setup\nlibrary(tidyverse)\nlibrary(dunnr)\nlibrary(gt)\nlibrary(broom)\nlibrary(patchwork)\n\nextrafont::loadfonts(device = \"win\", quiet = TRUE)\ntheme_set(theme_td())\nset_geom_fonts()\nset_palette()\n\nwine_red <- \"#58181F\"\nupdate_geom_defaults(\"point\", list(color = wine_red))\nupdate_geom_defaults(\"line\", list(color = wine_red))\nThe purpose of this post is to learn more about ordinal regression models (a.k.a. cumulative link, proportional odds, ordered logit models, etc.) and practice their implementation in R. This is part 1, where I’ll be taking the frequentist approach via the ordinal package. There are other options, like MASS::polr, but two features in particular drew me to ordinal: (1) it allows for random effects, and (2) it has broom::tidy methods available.\nParticularly, I’ll be following along with"
  },
  {
    "objectID": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#setup",
    "href": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#setup",
    "title": "Ordinal regression in R: part 1",
    "section": "Setup",
    "text": "Setup\nImport ordinal, and the included data set wine:\n\nlibrary(ordinal)\ndata(wine)\nwine <- as_tibble(wine)\nglimpse(wine)\n\nRows: 72\nColumns: 6\n$ response <dbl> 36, 48, 47, 67, 77, 60, 83, 90, 17, 22, 14, 50, 30, 51, 90, 7…\n$ rating   <ord> 2, 3, 3, 4, 4, 4, 5, 5, 1, 2, 1, 3, 2, 3, 5, 4, 2, 3, 3, 2, 5…\n$ temp     <fct> cold, cold, cold, cold, warm, warm, warm, warm, cold, cold, c…\n$ contact  <fct> no, no, yes, yes, no, no, yes, yes, no, no, yes, yes, no, no,…\n$ bottle   <fct> 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5…\n$ judge    <fct> 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3…\n\n\nwine is a data set from Randall (1989) of wine bitterness ratings from multiple judges. The variables are as follows:\n\nOutcome:\n\nresponse: wine bitterness rating on a 0-100 scale\nrating: ordered factor with 5 levels (grouped version of response) with 1 = “least bitter” and 5 = “most bitter”\n\nTreatment factors:\n\ntemp: temperature during wine production (cold and warm)\ncontact: contact between juice and skins during wine production (no and yes)\n\nRandom effects\n\nbottle with 8 levels\njudge with 9 levels\n\n\nRelationship between response and rating:\n\nwine %>%\n  ggplot(aes(y = rating, x = response)) +\n  geom_boxplot(width = 0.5) +\n  geom_jitter(alpha = 0.5)\n\n\n\n\nNote that there is no overlap between the levels.\nThere are 72 total observations with the following ratings distribution by treatment and random effects:\n\nwine %>%\n  transmute(temp, contact, bottle, judge, rating = as.numeric(rating)) %>%\n  pivot_wider(names_from = judge, values_from = rating) %>%\n  gt() %>%\n  tab_spanner(columns = `1`:`9`, label = \"judge\") %>%\n  data_color(\n    columns = `1`:`9`,\n    colors = scales::col_numeric(\n      palette = c(\"white\", wine_red), domain = c(1, 5)\n    )\n  )\n\n\n\n\n\n  \n  \n    \n      temp\n      contact\n      bottle\n      \n        judge\n      \n    \n    \n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n    \n  \n  \n    cold\nno\n1\n2\n1\n2\n3\n2\n3\n1\n2\n1\n    cold\nno\n2\n3\n2\n3\n2\n3\n2\n1\n2\n2\n    cold\nyes\n3\n3\n1\n3\n3\n4\n3\n2\n2\n3\n    cold\nyes\n4\n4\n3\n2\n2\n3\n2\n2\n3\n2\n    warm\nno\n5\n4\n2\n5\n3\n3\n2\n2\n3\n3\n    warm\nno\n6\n4\n3\n5\n2\n3\n4\n3\n3\n2\n    warm\nyes\n7\n5\n5\n4\n5\n3\n5\n2\n3\n4\n    warm\nyes\n8\n5\n4\n4\n3\n3\n4\n3\n4\n4\n  \n  \n  \n\n\n\n\nSo each bottle had a particular temp and contact (2 bottles for each of the 4 combinations), and each judge rated the bitterness each bottle.\nBefore modeling, can we see a clear effect of temp and contact?\n\nwine %>%\n  count(contact, rating, temp) %>%\n  mutate(temp = fct_rev(temp)) %>%\n  ggplot(aes(x = temp, y = rating, color = temp)) +\n  geom_point(aes(group = temp, size = n)) +\n  facet_wrap(~contact, scales = \"free_x\",\n             labeller = labeller(contact = label_both)) +\n  scale_size(breaks = c(1, 2, 4, 6, 8)) +\n  add_facet_borders()\n\n\n\n\nAt a glance, it looks like the temp = warm and contact = yes is associated with higher ratings."
  },
  {
    "objectID": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#the-cumulative-link-model",
    "href": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#the-cumulative-link-model",
    "title": "Ordinal regression in R: part 1",
    "section": "The cumulative link model",
    "text": "The cumulative link model\n\nTheory\nThe ordinal response \\(y_i\\) falls into response category \\(j\\) (out of \\(J\\) total) with probability \\(\\pi_{ij}\\). The cumulative probabilities are defined:\n\\[\nP(y_i \\leq j) = \\pi_{i1} + \\dots + \\pi_{ij}.\n\\]\nAs an oversimplification, suppose that each probability \\(\\pi_{ij}\\) is equal to the proportion of that response in the wine data. Then the cumulative “probability” can be visualized:\n\nwine_prop <- wine %>%\n  count(rating) %>%\n  mutate(p = n / sum(n), cumsum_p = cumsum(p))\n\n(\n  ggplot(wine_prop, aes(x = rating, y = p)) +\n    geom_col(fill = wine_red) +\n    scale_y_continuous(labels = scales::percent, expand = c(0, 0)) +\n    labs(x = \"j\", y = \"proportion\")\n) +\n  (\n    ggplot(wine_prop, aes(x = as.integer(rating), y = cumsum_p)) +\n      geom_point(size = 2) +\n      geom_line(size = 1) +\n      labs(x = \"j\", y = \"cumulative proportion\")\n  ) +\n  (\n    ggplot(wine_prop,\n        aes(x = as.integer(rating), y = log(cumsum_p) - log(1 - cumsum_p))) +\n      geom_point(size = 2) +\n      geom_line(size = 1) +\n      labs(x = \"j\", y = \"logit(cumulative proportion)\")\n  )\n\n\n\n\nWe will explore other links, but first the most common, the logit link, which is depicted in the right-most panel of the above figure:\n\\[\n\\text{logit} (P(y_i \\leq j) = \\log \\frac{P(y_i \\leq j)}{1 - P(y_i \\leq j)}\n\\]\nNote that the above function is defined for all but the last category \\(j = J\\), because \\(1 - P(Y_i \\leq J) = 1 - 1 = 0\\).\nFor the wine data, where we have \\(J\\) = 5 rating categories, we will build up to the following mixed effects model:\n\\[\n\\begin{align}\n\\text{logit}(p(y_i \\leq j)) &= \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i - u( \\text{judge}_i) \\\\\ni &= 1, \\dots n \\; \\; \\; \\; \\; \\; j = 1, \\dots, J - 1\n\\end{align}\n\\]\nwhere \\(\\theta_j\\) is called the threshold parameter, or cutpoint, of category \\(j\\). These thresholds can also be thought of as \\(J-1\\) = 4 intercepts. Note that the fixed effect parameters \\(\\beta_1\\) and \\(\\beta_2\\) are independent of \\(j\\), so each \\(\\beta\\) has the same effect for each of the \\(J-1\\) cumulative logits. The judge effects, which are also independent of \\(j\\), are assumed normal: \\(u(\\text{judge}_i) \\sim N(0, \\sigma_u^2)\\). We are using the logit link because it is the most popular for this kind of model (and the one I am familiar with), but there are other options we will briefly explore later.\nThe subtraction of terms in the above model is new to me. The main reason seems to be for familiar interpretation: the larger the value of any independent term \\(\\beta x\\), the smaller the thresholds \\(\\theta_j\\), and therefore a larger probability of the a response falling into a category at the upper end of the scale. This way, \\(\\beta\\) has the same direction of effect as in ordinary linear regression.\nWe are essentially modeling a “chain” of logistic regressions where the binary response is “less than or equal to a certain level” vs “greater than that level”. In this case, with \\(J\\) = 5, the thresholds \\(\\theta_j\\) are capturing the adjusted log-odds of observing:\n\n\\(j\\) = 1: log-odds of rating = 1 vs. 2-5\n\\(j\\) = 2: log-odds of rating = 1-2 vs. 3-5\n\\(j\\) = 3: log-odds of rating = 1-3 vs. 4-5\n\\(j\\) = 4: log-odds of rating = 1-4 vs. 5\n\n\n\nFitting\nNow with a surface-level understanding of what is being modeled, we will fit the data using ordinal::clm (cumulative link models) and ordinal::clmm (cumulative link mixed models), and logit links.\n\nFixed effects model\nFirst, fit a simple model, by maximum likelihood, with contact as the sole predictor:\n\\[\n\\text{logit}(p(y_i \\leq j)) = \\theta_j - \\beta_2 \\text{contact}_i\n\\]\n\nclm_rating_contact <-\n  clm(\n    rating ~ contact,\n    data = wine, link = \"logit\"\n  )\nsummary(clm_rating_contact)\n\nformula: rating ~ contact\ndata:    wine\n\n link  threshold nobs logLik AIC    niter max.grad cond.H \n logit flexible  72   -99.96 209.91 5(0)  1.67e-07 1.7e+01\n\nCoefficients:\n           Estimate Std. Error z value Pr(>|z|)   \ncontactyes   1.2070     0.4499   2.683   0.0073 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -2.13933    0.48981  -4.368\n2|3  0.04257    0.32063   0.133\n3|4  1.71449    0.38637   4.437\n4|5  2.97875    0.50207   5.933\n\n\nThe model gives us \\(K - 1 = 4\\) threshold coefficients, as expected. The \\(\\beta_2\\) coefficient estimate was statistically significant (by a Wald test), and tells us that contact = yes decreases the thresholds \\(\\theta_j\\) by \\(\\beta_2\\) = 1.21 (because of the subtraction of model terms), and therefore is associated with higher ratings.\nThe condition number of the Hessian for this model is 16.98. The ordinal primer says that larger values (like > 1e4) might indicate that the model is ill-defined.\nIt is nicely illustrative to compare this model to 4 separate logistic regressions with a dichotomized response:\n\\[\n\\begin{align}\n\\text{logit} (p(y_i \\leq 1)) &= \\theta_1 + \\beta_2 \\text{contact}_i \\\\\n\\text{logit} (p(y_i \\leq 2)) &= \\theta_2 + \\beta_2 \\text{contact}_i \\\\\n\\text{logit} (p(y_i \\leq 3)) &= \\theta_3 + \\beta_2 \\text{contact}_i \\\\\n\\text{logit} (p(y_i \\leq 4)) &= \\theta_4 + \\beta_2 \\text{contact}_i\n\\end{align}\n\\]\n\nwine %>%\n  crossing(j = 1:4) %>%\n  # Create a binary (0 or 1) to indicate where rating <= j\n  mutate(rating_leq_j = as.numeric(rating) <= j) %>%\n  group_by(j) %>%\n  nest() %>%\n  ungroup() %>%\n  mutate(\n    mod = map(\n      data,\n      ~glm(rating_leq_j ~ 1 + contact,\n           data = ., family = binomial(link = \"logit\")) %>% broom::tidy()\n    )\n  ) %>%\n  unnest(mod) %>%\n  transmute(\n    j, term,\n    estimate_se = str_c(round(estimate, 2), \" (\", round(std.error, 2), \")\")\n  ) %>%\n  pivot_wider(names_from = term, values_from = estimate_se) %>%\n  left_join(\n    tidy(clm_rating_contact) %>%\n      transmute(\n        j = as.integer(substr(term, 1, 1)),\n        term = if_else(!is.na(j), \"theta_j\", term),\n        estimate_se = str_c(round(estimate, 2), \" (\", round(std.error, 2), \")\")\n      ) %>%\n      mutate(j = replace_na(j, 1)) %>%\n      spread(term, estimate_se),\n    by = \"j\"\n  ) %>%\n  ungroup() %>%\n  gt() %>%\n  tab_spanner(label = \"Logistic regression\",\n              columns = c(`(Intercept)`, contactyes.x)) %>%\n  tab_spanner(label = \"CLM\",\n              columns = c(theta_j, contactyes.y)) %>%\n  fmt_missing(columns = everything(), missing_text = \"\")\n\n\n\n\n\n  \n  \n    \n      j\n      \n        Logistic regression\n      \n      \n        CLM\n      \n    \n    \n      (Intercept)\n      contactyes.x\n      theta_j\n      contactyes.y\n    \n  \n  \n    1\n-2.08 (0.53)\n-1.48 (1.14)\n-2.14 (0.49)\n1.21 (0.45)\n    2\n0 (0.33)\n-1.1 (0.51)\n0.04 (0.32)\n\n    3\n1.82 (0.48)\n-1.37 (0.59)\n1.71 (0.39)\n\n    4\n2.83 (0.73)\n-1.01 (0.87)\n2.98 (0.5)\n\n  \n  \n  \n\n\n\n\nThe intercepts from the ordinary logistic regression correspond closely to the threshold parameters \\(\\theta_j\\) from the cumulative link model. In the fixed effect of contact (\\(\\beta_2\\)), first note the sign difference, and second notice that the estimate from CLM is about the average of the 4 estimates from logistic regression. The advantage of the CLM is seen in the small standard error in the \\(\\beta_2\\) estimate.\nTo quote the primer:\n\nThe cumulative logit model can be seen as the model that combines these four ordinary logistic regression models into a single model and therefore makes better use of the information in the data.\n\nFor the second model, we add the \\(\\beta_1 \\text{temp}_i\\) term:\n\\[\n\\text{logit}(p(y_i \\leq j)) = \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i\n\\]\n\nclm_rating_contact_temp <-\n  clm(\n    rating ~ contact + temp,\n    data = wine, link = \"logit\"\n  )\nsummary(clm_rating_contact_temp)\n\nformula: rating ~ contact + temp\ndata:    wine\n\n link  threshold nobs logLik AIC    niter max.grad cond.H \n logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01\n\nCoefficients:\n           Estimate Std. Error z value Pr(>|z|)    \ncontactyes   1.5278     0.4766   3.205  0.00135 ** \ntempwarm     2.5031     0.5287   4.735 2.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -1.3444     0.5171  -2.600\n2|3   1.2508     0.4379   2.857\n3|4   3.4669     0.5978   5.800\n4|5   5.0064     0.7309   6.850\n\n\nBoth fixed effects (contact = yes and temp = warm) are strongly associated with higher probability of higher ratings. The summary function provides \\(p\\)-values from Wald tests, but more accurate likelihood ratio tests can be done via the drop1 function, which evaluates each fixed effect while controlling the other:\n\ndrop1(clm_rating_contact_temp, test = \"Chisq\")\n\nSingle term deletions\n\nModel:\nrating ~ contact + temp\n        Df    AIC    LRT  Pr(>Chi)    \n<none>     184.98                     \ncontact  1 194.03 11.043 0.0008902 ***\ntemp     1 209.91 26.928 2.112e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOr the reverse via the add1() function, which evaluates each fixed effect while ignoring the other:\n\n# Fit the null model first\nclm_rating_null <- clm(rating ~ 1, data = wine, link = \"logit\")\nadd1(clm_rating_null, scope = ~ contact + temp, test = \"Chisq\")\n\nSingle term additions\n\nModel:\nrating ~ 1\n        Df    AIC     LRT  Pr(>Chi)    \n<none>     215.44                      \ncontact  1 209.91  7.5263   0.00608 ** \ntemp     1 194.03 23.4113 1.308e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSymmetric Wald confidence intervals can be extracted with confint or with broom::tidy:\n\ntidy(clm_rating_contact_temp, conf.int = TRUE, conf.type = \"Wald\") %>%\n  ggplot(aes(y = term, x = estimate)) +\n  geom_point(size = 2) +\n  geom_linerange(size = 1, aes(xmin = conf.low, xmax = conf.high))\n\n\n\n\nIn these types of analyses, we are often interested in the odds ratios. For the two categorical fixed effects, which have two levels each, the odds ratios \\(y \\leq j\\) comparing the two levels are:\n\\[\n\\begin{align}\n\\text{OR} &= \\frac{\\gamma_j (\\text{temp} = \\text{warm})}{\\gamma_j (\\text{temp} = \\text{cold})} = \\frac{\\exp(\\theta_j - \\beta_1 - \\beta_2 \\text{contact})}{\\exp (\\theta_j - 0 - \\beta_2 \\text{contact}}) = \\exp(\\beta_1) \\\\\n\\text{OR} &= \\frac{\\gamma_j (\\text{contact} = \\text{yes})}{\\gamma_j (\\text{contact} = \\text{no})} = \\frac{\\exp(\\theta_j - \\beta_1 \\text{temp} - \\beta_2 )}{\\exp (\\theta_j - \\beta_1 \\text{temp} - 0)}) = \\exp(\\beta_2)\n\\end{align}\n\\]\nwhere we have introduced the shorthand \\(\\gamma_j = \\text{logit} (p(y \\leq j))\\). Compute those odds ratios, and their corresponding Wald 95% CIs:\n\ntidy(clm_rating_contact_temp, conf.int = T, conf.type = \"Wald\") %>%\n  transmute(\n    term, across(c(estimate, conf.low, conf.high), exp)\n  ) %>%\n  gt() %>%\n  fmt_number(c(estimate, conf.low, conf.high), decimals = 2)\n\n\n\n\n\n  \n  \n    \n      term\n      estimate\n      conf.low\n      conf.high\n    \n  \n  \n    1|2\n0.26\n0.09\n0.72\n    2|3\n3.49\n1.48\n8.24\n    3|4\n32.04\n9.93\n103.39\n    4|5\n149.37\n35.65\n625.75\n    contactyes\n4.61\n1.81\n11.73\n    tempwarm\n12.22\n4.34\n34.44\n  \n  \n  \n\n\n\n\nOne last thing to check: does the data support an interaction between \\(\\text{temp}_i\\) and \\(\\text{contact}_i\\)?\n\\[\n\\text{logit}(p(y_i \\leq j)) = \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i - \\beta_3 \\text{temp}_i \\text{contact}_i\n\\]\n\nclm_rating_contact_temp_inter <-\n  clm(\n    rating ~ contact * temp, data = wine, link = \"logit\"\n  )\n\n#drop1(clm_rating_contact_temp_inter, test = \"Chisq\") # this accomplishes the same thing as anova()\nanova(clm_rating_contact_temp, clm_rating_contact_temp_inter)\n\nLikelihood ratio tests of cumulative link models:\n \n                              formula:                link: threshold:\nclm_rating_contact_temp       rating ~ contact + temp logit flexible  \nclm_rating_contact_temp_inter rating ~ contact * temp logit flexible  \n\n                              no.par    AIC  logLik LR.stat df Pr(>Chisq)\nclm_rating_contact_temp            6 184.98 -86.492                      \nclm_rating_contact_temp_inter      7 186.83 -86.416  0.1514  1     0.6972\n\n\nNo, The interaction term contact:temp is not supported by the data.\n\nComparison to linear model\nConsider the following linear model which treats rating as continuous:\n\\[\ny_i = \\alpha + \\beta_1 \\text{temp}_i + \\beta_2 \\text{contact}_i + \\epsilon_i\n\\]\nwhere \\(\\epsilon_i \\sim N(0, \\sigma_{\\epsilon}^2)\\).\n\nlm_rating_contact_temp <- lm(as.numeric(rating) ~ contact + temp, data = wine)\n\nTo compare this to a CLM, we must use the probit link:\n\nclm_rating_contact_temp_probit <-\n  clm(\n    rating ~ contact + temp, data = wine, link = \"probit\"\n  )\ntidy(clm_rating_contact_temp_probit) %>%\n  filter(coef.type == \"location\") %>%\n  mutate(model = \"CLM\") %>%\n  select(-coef.type) %>%\n  bind_rows(\n    tidy(lm_rating_contact_temp) %>%\n      filter(term != \"(Intercept)\") %>%\n      # Need to divide by the residual SE here to get the right scale\n      mutate(estimate = estimate / summary(lm_rating_contact_temp)$sigma,\n             model = \"LM\")\n  ) %>%\n  group_by(model) %>%\n  gt() %>%\n  fmt_number(c(estimate, std.error, statistic), decimals = 2) %>%\n  fmt(p.value, fns = scales::pvalue)\n\n\n\n\n\n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    \n      CLM\n    \n    contactyes\n0.87\n0.27\n3.25\n0.001\n    tempwarm\n1.50\n0.29\n5.14\n<0.001\n    \n      LM\n    \n    contactyes\n0.79\n0.20\n3.36\n0.001\n    tempwarm\n1.38\n0.20\n5.87\n<0.001\n  \n  \n  \n\n\n\n\nThe relative estimates from the linear model are lower than those from the CLM (probit link), indicating that the assumptions of the linear model are not met. In particular, the distance between thresholds is not equidistant, as we can see from differences in the CLM coefficients:\n\ndiff(coef(clm_rating_contact_temp_probit)[1:4]) %>% round(2)\n\n 2|3  3|4  4|5 \n1.51 1.31 0.90 \n\n\n\n\n\nMixed effects model\nNow that we have explored ordinal regression with just fixed effects, we will fit the following random effects model:\n\\[\n\\begin{align}\n\\text{logit}(p(y_i \\leq j)) &= \\theta_j - \\beta_1 \\text{temp}_i - \\beta_2 \\text{contact}_i - u( \\text{judge}_i) \\\\\ni &= 1, \\dots n \\; \\; \\; \\; \\; \\; j = 1, \\dots, J - 1\n\\end{align}\n\\]\nwhere the judge effects are independent of \\(j\\), and assumed normal: \\(u(\\text{judge}_i) \\sim N(0, \\sigma_u^2)\\).\nEach judge has 8 ratings each (two per combination of temp and contact). See if we can spot the judge variance in a plot of ratings:\n\nwine %>%\n  count(judge, rating) %>%\n  ggplot(aes(x = judge, y = rating)) +\n  geom_tile(aes(fill = n)) +\n  geom_text(aes(label = n), color = \"white\") +\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0)) +\n  theme(legend.position = \"none\") +\n  labs(title = \"Number of ratings by judge\")\n\n\n\n\nThere is definitely some judge-specific variability in the perception of bitterness of wine. judge 5, for instance, doesn’t stray far from rating = 3, while judge 7 didn’t consider any of the wines particularly bitter.\nFit the full model with ordinal::clmm and logit link:\n\nclmm_rating_contact_temp <-\n  clmm(\n    rating ~ temp + contact + (1|judge),\n    data = wine, link = \"logit\"\n  )\n# This is an older function, which we need to run stats::profile later\nclmm2_rating_contact_temp <-\n  clmm2(\n    rating ~ temp + contact, random = judge,\n    data = wine, link = \"logistic\"\n  )\nsummary(clmm_rating_contact_temp)\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ temp + contact + (1 | judge)\ndata:    wine\n\n link  threshold nobs logLik AIC    niter    max.grad cond.H \n logit flexible  72   -81.57 177.13 332(999) 1.03e-05 2.8e+01\n\nRandom effects:\n Groups Name        Variance Std.Dev.\n judge  (Intercept) 1.279    1.131   \nNumber of groups:  judge 9 \n\nCoefficients:\n           Estimate Std. Error z value Pr(>|z|)    \ntempwarm     3.0630     0.5954   5.145 2.68e-07 ***\ncontactyes   1.8349     0.5125   3.580 0.000344 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -1.6237     0.6824  -2.379\n2|3   1.5134     0.6038   2.507\n3|4   4.2285     0.8090   5.227\n4|5   6.0888     0.9725   6.261\n\n\nCompare model coefficients:\n\nbind_rows(\n  CLM = tidy(clm_rating_contact_temp),\n  CLMM = tidy(clmm_rating_contact_temp),\n  .id = \"model\"\n) %>%\n  select(-coef.type) %>%\n  group_by(model) %>%\n  gt() %>%\n  fmt_number(c(estimate, std.error, statistic), decimals = 2) %>%\n  fmt(p.value, fns = scales::pvalue)\n\n\n\n\n\n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    \n      CLM\n    \n    1|2\n−1.34\n0.52\n−2.60\n0.009\n    2|3\n1.25\n0.44\n2.86\n0.004\n    3|4\n3.47\n0.60\n5.80\n<0.001\n    4|5\n5.01\n0.73\n6.85\n<0.001\n    contactyes\n1.53\n0.48\n3.21\n0.001\n    tempwarm\n2.50\n0.53\n4.73\n<0.001\n    \n      CLMM\n    \n    1|2\n−1.62\n0.68\n−2.38\n0.017\n    2|3\n1.51\n0.60\n2.51\n0.012\n    3|4\n4.23\n0.81\n5.23\n<0.001\n    4|5\n6.09\n0.97\n6.26\n<0.001\n    tempwarm\n3.06\n0.60\n5.14\n<0.001\n    contactyes\n1.83\n0.51\n3.58\n<0.001\n  \n  \n  \n\n\n\n\nBoth fixed effect estimates \\(\\beta_1\\) and \\(\\beta_2\\) are higher in the CLMM. Use anova to compare the CLMM to the CLM:\n\nanova(clm_rating_contact_temp, clmm_rating_contact_temp)\n\nLikelihood ratio tests of cumulative link models:\n \n                         formula:                              link: threshold:\nclm_rating_contact_temp  rating ~ contact + temp               logit flexible  \nclmm_rating_contact_temp rating ~ temp + contact + (1 | judge) logit flexible  \n\n                         no.par    AIC  logLik LR.stat df Pr(>Chisq)   \nclm_rating_contact_temp       6 184.98 -86.492                         \nclmm_rating_contact_temp      7 177.13 -81.565   9.853  1   0.001696 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nUnsurprisingly, the judge term makes a significant improvement to the fit. We can extract profile confidence intervals on the variance \\(\\sigma_u\\) using stats::profile:\n\nprofile(clmm2_rating_contact_temp,\n        range = c(0.1, 4), nSteps = 30, trace = 0) %>%\n  confint()\n\n          2.5 %  97.5 %\nstDev 0.5014584 2.26678\n\n\nNote that these intervals are asymmetric (\\(\\sigma_u\\) = 1.28), unlike the less accurate Wald tests. We can produce “best guess” estimates for judge effects using conditional modes:\n\ntibble(\n  judge_effect = clmm_rating_contact_temp$ranef,\n  cond_var = clmm_rating_contact_temp$condVar\n) %>%\n  mutate(\n    judge = fct_reorder(factor(1:n()), judge_effect),\n    conf.low = judge_effect - qnorm(0.975) * sqrt(cond_var),\n    conf.high = judge_effect + qnorm(0.975) * sqrt(cond_var)\n  ) %>%\n  ggplot(aes(y = judge, x = judge_effect)) +\n  geom_point(size = 2) +\n  geom_linerange(size = 1, aes(xmin = conf.low, xmax = conf.high)) +\n  theme(panel.grid.major.x = element_line(color = \"grey\"))\n\n\n\n\n\nPredictions\nThere are different ways to extract predicted probabilities. First, and most obviously, with the predict function:\n\nwine %>%\n  bind_cols(\n    pred =  predict(\n      # Have to use clmm2 for predict\n      clmm2_rating_contact_temp, newdata = wine\n    )\n  ) %>%\n  # These are predicted probabilities for the average judge, so we can\n  #  exclude the judge variable\n  distinct(rating, temp, contact, pred) %>%\n  arrange(temp, contact, rating)\n\n# A tibble: 15 × 4\n   rating temp  contact   pred\n   <ord>  <fct> <fct>    <dbl>\n 1 1      cold  no      0.165 \n 2 2      cold  no      0.655 \n 3 3      cold  no      0.166 \n 4 1      cold  yes     0.0305\n 5 2      cold  yes     0.390 \n 6 3      cold  yes     0.496 \n 7 4      cold  yes     0.0696\n 8 2      warm  no      0.166 \n 9 3      warm  no      0.587 \n10 4      warm  no      0.191 \n11 5      warm  no      0.0463\n12 2      warm  yes     0.0313\n13 3      warm  yes     0.306 \n14 4      warm  yes     0.428 \n15 5      warm  yes     0.233 \n\n\nThis only gives us predictions for rating, temp and contact values which exist in the data. There is no predicted probability for rating > 3, temp cold and contact no, for example.\nAnother way is to pre-specify which values we want to predict:\n\nnd <-\n  crossing(\n    temp = factor(c(\"cold\", \"warm\")),\n    contact = factor(c(\"no\", \"yes\")),\n    rating = factor(1:5, ordered = T)\n  )\nnd %>%\n  bind_cols(pred = predict(clmm2_rating_contact_temp, nd)) %>%\n  ggplot(aes(x = glue::glue(\"{temp}-{contact}\"), y = pred, fill = rating)) +\n  geom_col() +\n  scale_fill_td(palette = \"div5\") +\n  scale_y_continuous(expand = c(0, 0), labels = scales::percent) +\n  labs(x = \"temp-contact\", y = \"predicted probability\")\n\n\n\n\nWe can also get model-estimated cumulative probabilities by considering the model coefficients. For example, for a cold temp and contact, the cumulative probability of a bitterness rating \\(j\\) or less:\n\\[\nP(y_i \\leq j) = \\text{logit}^{-1} [\\theta_j - \\beta_2 \\text{contact}_i]\n\\]\nwhere we are considering the average judge (\\(u(\\text{judge}_i) = 0\\)). The inverse logit is \\(\\text{logit}^{-1}(x) = 1 / (1 + \\exp(-x))\\), and can be calculated with plogis as a shorthand (brms::inv_logit_scaled is another). We can subtract cumulative probabilities to get non-cumulative probabilities of a rating \\(j\\). For example, \\(j\\) = 3:\n\nplogis(clmm_rating_contact_temp$Theta[3] - clmm_rating_contact_temp$beta[2]) -\n  plogis(clmm_rating_contact_temp$Theta[2] - clmm_rating_contact_temp$beta[2])\n\ncontactyes \n 0.4960357 \n\n\nwhich matches the value calculated previously using predict.\n\n\nEstimated marginal means\nThe emmeans package provides functionality for estimating marginal mean effects of ordinal models. The package documentation also provides an example using ordinal and wine data here.\n\nlibrary(emmeans)\n\nIn the “Models supported by emmeans” document, we see the following:\n\n\n\n\n\n\n\n\n\n\nObject.class\nPackage\nGroup\nArguments/notes\n\n\n\n\n\nclm\nordinal\nO\nmode = c(\"latent\", \"linear.predictor\", \"cum.prob\", \"exc.prob\", \"prob\", \"mean.class\", \"scale\")\n\n\n\nclmm\nordinal\nO\nLike clm but no \"scale\" mode\n\n\n\n\n\n\n\n\n\n\n\n\nemmeans(clmm_rating_contact_temp,\n        specs = list(pairwise ~ temp, pairwise ~ contact), mode = \"latent\")\n\n$`emmeans of temp`\n temp emmean    SE  df asymp.LCL asymp.UCL\n cold  -1.63 0.547 Inf    -2.707    -0.562\n warm   1.43 0.532 Inf     0.387     2.470\n\nResults are averaged over the levels of: contact \nConfidence level used: 0.95 \n\n$`pairwise differences of temp`\n 1           estimate    SE  df z.ratio p.value\n cold - warm    -3.06 0.595 Inf  -5.145  <.0001\n\nResults are averaged over the levels of: contact \n\n$`emmeans of contact`\n contact emmean    SE  df asymp.LCL asymp.UCL\n no      -1.020 0.522 Inf    -2.043   0.00274\n yes      0.815 0.513 Inf    -0.191   1.82072\n\nResults are averaged over the levels of: temp \nConfidence level used: 0.95 \n\n$`pairwise differences of contact`\n 1        estimate    SE  df z.ratio p.value\n no - yes    -1.83 0.513 Inf  -3.580  0.0003\n\nResults are averaged over the levels of: temp \n\n\nThe contrast estimates are in terms of the latent (underlying unobserved) bitterness rating.\nUsing mode = \"cum.prob\" and mode = \"exc.prob“, we can get cumulative probabilities and exceedance (1 - cumulative) probabilities. For example, the probability of a rating of at least 4 for different temp:\n\nemmeans(clmm_rating_contact_temp, ~ temp,\n        mode = \"exc.prob\", at = list(cut = \"3|4\"))\n\n temp exc.prob     SE  df asymp.LCL asymp.UCL\n cold    0.049 0.0304 Inf   -0.0107     0.109\n warm    0.450 0.1084 Inf    0.2371     0.662\n\nResults are averaged over the levels of: contact \nConfidence level used: 0.95 \n\n\nmode = \"prob\" gives us probability distributions of each rating, which have a nice auto plot functionality:\n\nemmeans(clmm_rating_contact_temp,\n        ~ rating | temp, mode = \"prob\") %>%\n  plot() +\n  add_facet_borders()\n\n\n\n\n\n\nChoice of link function\nSo far, we have used the logit link (and briefly the probit link to compare estimates with linear regression). The links available to ordinal::clmm are logit, probit, cloglog, loglog, and cauchit.\nWe can fit the CLMM using all of these links and compare log-likelihoods:\n\nwine %>%\n  nest(data = everything()) %>%\n  crossing(\n    link = c(\"logit\", \"probit\", \"cloglog\", \"loglog\", \"cauchit\")\n  ) %>%\n  mutate(\n    mod = map2(\n      data, link,\n      ~clmm(\n        rating ~ 1 + contact + temp + (1|judge),\n        data = .x, link = .y\n      )\n    )\n  ) %>%\n  mutate(mod_summary = map(mod, glance)) %>%\n  unnest(mod_summary) %>%\n  select(link, logLik, AIC, BIC) %>%\n  arrange(logLik) %>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      link\n      logLik\n      AIC\n      BIC\n    \n  \n  \n    cauchit\n-86.83499\n187.6700\n203.6066\n    cloglog\n-82.72936\n179.4587\n195.3954\n    logit\n-81.56541\n177.1308\n193.0675\n    loglog\n-81.54137\n177.0827\n193.0194\n    probit\n-80.93061\n175.8612\n191.7979\n  \n  \n  \n\n\n\n\nThe probit model appears to be the best description of the data.\nWe can also consider the effect of “flexible” vs “equidistant” thresholds:\n\nwine %>%\n  nest(data = everything()) %>%\n  crossing(\n    link = c(\"logit\", \"probit\", \"cloglog\", \"loglog\", \"cauchit\"),\n    threshold = c(\"flexible\", \"equidistant\")\n  ) %>%\n  mutate(\n    mod = pmap(\n      list(data, link, threshold),\n      function(a, b, c) {\n        clmm(\n          rating ~ 1 + contact + temp + (1|judge),\n          data = a, link = b, threshold = c\n        )\n      }\n    )\n  ) %>%\n  #mutate(mod_summary = map(mod, glance)) %>%\n  mutate(\n    mod_summary = map(\n      mod,\n      # glance() on a clmm object returns a <logLik> variable type which\n      #  can't be bound together by unnest(), so need to convert it to numeric\n      ~glance(.x) %>% mutate(logLik = as.numeric(logLik))\n    )\n  ) %>%\n  unnest(mod_summary) %>%\n  select(link, threshold, logLik, edf, AIC, BIC) %>%\n  arrange(logLik) %>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      link\n      threshold\n      logLik\n      edf\n      AIC\n      BIC\n    \n  \n  \n    cauchit\nequidistant\n-87.75021\n5\n185.5004\n196.8837\n    cauchit\nflexible\n-86.83499\n7\n187.6700\n203.6066\n    loglog\nequidistant\n-84.36440\n5\n178.7288\n190.1121\n    cloglog\nequidistant\n-83.32634\n5\n176.6527\n188.0360\n    logit\nequidistant\n-83.05497\n5\n176.1099\n187.4933\n    cloglog\nflexible\n-82.72936\n7\n179.4587\n195.3954\n    probit\nequidistant\n-82.52622\n5\n175.0524\n186.4358\n    logit\nflexible\n-81.56541\n7\n177.1308\n193.0675\n    loglog\nflexible\n-81.54137\n7\n177.0827\n193.0194\n    probit\nflexible\n-80.93061\n7\n175.8612\n191.7979\n  \n  \n  \n\n\n\n\nNote the change in degrees of freedom, resulting in the equidistant probit model having the lowest BIC. In terms of log likelihood, however, flexible always outperform equidistant thresholds."
  },
  {
    "objectID": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#conclusion",
    "href": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#conclusion",
    "title": "Ordinal regression in R: part 1",
    "section": "Conclusion",
    "text": "Conclusion\nThanks to detailed documentation, fitting cumulative link (mixed) models is very easy with ordinal. In this post, we first learned the theoretical basis for these models, then worked through examples using wine bitterness ratings from multiple judges.\nIn the next post, I’ll explore the Bayesian approach to ordinal regression with the brms package."
  },
  {
    "objectID": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#reproducibility",
    "href": "posts/2020-03-15-ordinal-regression-in-r-part-1/ordinal-regression-in-r-part-1.html#reproducibility",
    "title": "Ordinal regression in R: part 1",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\n\nSession info\n\n\n\n setting  value\n version  R version 4.2.1 (2022-06-23 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Canada.utf8\n ctype    English_Canada.utf8\n tz       America/Curacao\n date     2022-08-06\n pandoc   2.18 @ C:/Program Files/RStudio/bin/quarto/bin/tools/ (via rmarkdown)\n\n\n\n\n  \n\n\n\n\n\n\nGit repository\n\n\n\nLocal:    main C:/Users/tdunn/Documents/tdunn-quarto\nRemote:   main @ origin (https://github.com/taylordunn/tdunn-quarto.git)\nHead:     [b3046f5] 2022-07-13: Trying to get preview images working\n\n\n\n\n\nSource code"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{dunn2022,\n  author = {Taylor Dunn and Harlow Malloc},\n  title = {Post {With} {Code}},\n  date = {2022-07-12},\n  url = {https://tdunn.ca/posts/post-with-code},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nTaylor Dunn, and Harlow Malloc. 2022. “Post With Code.”\nJuly 12, 2022. https://tdunn.ca/posts/post-with-code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{dunn2022,\n  author = {Taylor Dunn and Tristan O’Malley},\n  title = {Welcome {To} {My} {Blog}},\n  date = {2022-07-09},\n  url = {https://tdunn.ca/posts/welcome},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nTaylor Dunn, and Tristan O’Malley. 2022. “Welcome To My\nBlog.” July 9, 2022. https://tdunn.ca/posts/welcome."
  }
]